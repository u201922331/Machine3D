{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa7b5765",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Users\\Usuario\\Documents\\GitHub\\Machine3D\\venv\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x224444b1010>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "seed = 1234\n",
    "torch.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acbc1a65",
   "metadata": {},
   "source": [
    "# Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0054c327",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = './'\n",
    "PATH_MODELS = PATH + '/models'\n",
    "PATH_MESHES = PATH + '/meshes'\n",
    "PATH_RESULTS = PATH + '/results'\n",
    "PATH_CHECKPOINTS_GEN = PATH + '/checkpoints/gen'\n",
    "PATH_CHECKPOINTS_DIS = PATH + '/checkpoints/dis'\n",
    "\n",
    "\n",
    "learning_rate = 0.00001\n",
    "epochs = 550\n",
    "\n",
    "mean_gen_loss = 0\n",
    "mean_dis_loss = 0\n",
    "\n",
    "LAMBDA = 100\n",
    "\n",
    "display_step = 500\n",
    "batch_size = 128\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3790709",
   "metadata": {},
   "source": [
    "# Load the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "86e83fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = np.load('./datasets/dataset.npy', allow_pickle=True).item()\n",
    "models_tr_x = models['train']['x']\n",
    "models_tr_y = models['train']['y']\n",
    "models_ts_x = models['test']['x']\n",
    "models_ts_y = models['test']['y']\n",
    "\n",
    "dl_tr = DataLoader(list(zip(models_tr_x, models_tr_y)), batch_size=batch_size, shuffle=True)\n",
    "dl_ts = DataLoader(list(zip(models_ts_x, models_ts_y)), batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48ef4635",
   "metadata": {},
   "source": [
    "# GAN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5ef7742",
   "metadata": {},
   "source": [
    "DownSamples y UpSamples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e58b26a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def downsample(channels_in, channels_out, batch=True, kernel_size=4, stride=1):\n",
    "    layers = []\n",
    "    layers.append(\n",
    "        nn.Conv3d(\n",
    "            channels_in,\n",
    "            channels_out,\n",
    "            kernel_size=kernel_size,\n",
    "            stride=stride,\n",
    "            bias=not batch\n",
    "        )\n",
    "    )\n",
    "    if batch:\n",
    "        layers.append(nn.BatchNorm3d(channels_out))\n",
    "    layers.append(nn.LeakyReLU(negative_slope=0.02))\n",
    "    return nn.Sequential(*layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "04c09016",
   "metadata": {},
   "outputs": [],
   "source": [
    "def upsample(channels_in, channels_out, dropout=False, kernel_size=4, stride=1):\n",
    "    layers = []\n",
    "    layers.append(\n",
    "        nn.ConvTranspose3d(\n",
    "            channels_in,\n",
    "            channels_out,\n",
    "            kernel_size=kernel_size,\n",
    "            stride=stride,\n",
    "            bias=False\n",
    "        )\n",
    "    )\n",
    "    layers.append(nn.BatchNorm3d(channels_out))\n",
    "    \n",
    "    if dropout:\n",
    "        layers.append(nn.Dropout3d(0.5))\n",
    "    layers.append(nn.ReLU())\n",
    "    return nn.Sequential(*layers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fead42ae",
   "metadata": {},
   "source": [
    "# Generador y Discriminador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3e8a1f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "        ff = 10\n",
    "        \n",
    "        self.down_stack = [\n",
    "            downsample(1, ff, batch=False),\n",
    "            downsample(ff, 2*ff),\n",
    "            downsample(2*ff, 4*ff, stride=2),\n",
    "            downsample(4*ff, 4*ff, stride=2),\n",
    "            downsample(4*ff, 4*ff, stride=2, batch=False)\n",
    "        ]\n",
    "        \n",
    "        self.up_stack = [\n",
    "            upsample(4*ff, 4*ff, dropout=False, kernel_size=5),\n",
    "            upsample(8*ff, 4*ff, dropout=False, stride=2),\n",
    "            upsample(8*ff, 2*ff, stride=2),\n",
    "            upsample(4*ff, ff)\n",
    "        ]\n",
    "        \n",
    "        self.result = nn.ConvTranspose3d(2*ff, 1, kernel_size=4)\n",
    "        self.act = nn.Tanh()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        s = []\n",
    "        \n",
    "        for elem in self.down_stack:\n",
    "            x = elem(x)\n",
    "            s.append(x)\n",
    "        \n",
    "        for i in range(len(self.up_stack)):\n",
    "            x = self.up_stack[i](x)\n",
    "            x = torch.cat((x, s[-(i+1)]), dim=1)\n",
    "        \n",
    "        return self.act(self.result(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "696ea9c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        \n",
    "        self.down_stack = [\n",
    "            downsample(2, 16, batch=False),\n",
    "            downsample(16, 32),\n",
    "            downsample(32, 64, stride=2),\n",
    "            downsample(64, 64, stride=2),\n",
    "            downsample(64, 64, stride=2)\n",
    "        ]\n",
    "        \n",
    "        self.result = nn.ConvTranspose3d(64, 1, kernel_size=4)\n",
    "        self.act = nn.Sigmoid()\n",
    "    \n",
    "    def forward(self, x, y):\n",
    "        x = torch.cat((x, y), dim=1)\n",
    "        \n",
    "        for elem in self.down_stack:\n",
    "            x = elem(x)\n",
    "        \n",
    "        return self.act(self.result(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8160a35d",
   "metadata": {},
   "source": [
    "# Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4200ca92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator_loss(criterion, real, fake):\n",
    "    dis_real_loss = criterion(real, torch.ones_like(real))\n",
    "    dis_fake_loss = criterion(fake, torch.zeros_like(fake))\n",
    "    \n",
    "    return (dis_fake_loss + dis_real_loss) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "59e57758",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator_loss(criterion, real_out, fake_out, target, fake, l):\n",
    "    dis_fake_loss = criterion(fake_out, torch.ones_like(fake_out))\n",
    "    target_loss = torch.mean(torch.abs(target - fake))\n",
    "    \n",
    "    return dis_fake_loss + l * target_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1954c037",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_epoch(data_in, data_fake, data_target):\n",
    "    fig = plt.figure()\n",
    "    ax1 = fig.add_subplot(1, 2, 1, projection='3d')\n",
    "    ax2 = fig.add_subplot(1, 2, 2, projection='3d')\n",
    "    \n",
    "    ax1.set_title('Input')\n",
    "    ax2.set_title('Fake')\n",
    "    \n",
    "    ax1.voxels(data_in > 0, facecolors='gray')\n",
    "    ax2.voxels(data_fake > 0, facecolors='red')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0a4038f",
   "metadata": {},
   "source": [
    "# Create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "81d29627",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = Generator()\n",
    "dis = Discriminator()\n",
    "\n",
    "gen_opt = torch.optim.Adam(gen.parameters(), lr=learning_rate)\n",
    "dis_opt = torch.optim.Adam(dis.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d4b4e198",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/8 [00:01<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Given groups=1, weight of size [10, 1, 4, 4, 4], expected input[1, 128, 32, 32, 32] to have 1 channels, but got 128 channels instead",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [13], line 10\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[39mfor\u001b[39;00m in_data, tg_data \u001b[39min\u001b[39;00m tqdm(dl_tr):\n\u001b[0;32m      9\u001b[0m     dis_opt\u001b[39m.\u001b[39mzero_grad()\n\u001b[1;32m---> 10\u001b[0m     fake \u001b[39m=\u001b[39m gen(in_data)\n\u001b[0;32m     11\u001b[0m     o_fake \u001b[39m=\u001b[39m dis(in_data, fake)\n\u001b[0;32m     12\u001b[0m     o_real \u001b[39m=\u001b[39m dis(in_data, tg_data)\n",
      "File \u001b[1;32md:\\Users\\Usuario\\Documents\\GitHub\\Machine3D\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "Cell \u001b[1;32mIn [6], line 28\u001b[0m, in \u001b[0;36mGenerator.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     25\u001b[0m s \u001b[39m=\u001b[39m []\n\u001b[0;32m     27\u001b[0m \u001b[39mfor\u001b[39;00m elem \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdown_stack:\n\u001b[1;32m---> 28\u001b[0m     x \u001b[39m=\u001b[39m elem(x)\n\u001b[0;32m     29\u001b[0m     s\u001b[39m.\u001b[39mappend(x)\n\u001b[0;32m     31\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mup_stack)):\n",
      "File \u001b[1;32md:\\Users\\Usuario\\Documents\\GitHub\\Machine3D\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32md:\\Users\\Usuario\\Documents\\GitHub\\Machine3D\\venv\\lib\\site-packages\\torch\\nn\\modules\\container.py:204\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    202\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[0;32m    203\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[1;32m--> 204\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[0;32m    205\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[1;32md:\\Users\\Usuario\\Documents\\GitHub\\Machine3D\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32md:\\Users\\Usuario\\Documents\\GitHub\\Machine3D\\venv\\lib\\site-packages\\torch\\nn\\modules\\conv.py:613\u001b[0m, in \u001b[0;36mConv3d.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    612\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m--> 613\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_conv_forward(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "File \u001b[1;32md:\\Users\\Usuario\\Documents\\GitHub\\Machine3D\\venv\\lib\\site-packages\\torch\\nn\\modules\\conv.py:608\u001b[0m, in \u001b[0;36mConv3d._conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    596\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mzeros\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m    597\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39mconv3d(\n\u001b[0;32m    598\u001b[0m         F\u001b[39m.\u001b[39mpad(\n\u001b[0;32m    599\u001b[0m             \u001b[39minput\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    606\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgroups,\n\u001b[0;32m    607\u001b[0m     )\n\u001b[1;32m--> 608\u001b[0m \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mconv3d(\n\u001b[0;32m    609\u001b[0m     \u001b[39minput\u001b[39;49m, weight, bias, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstride, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpadding, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdilation, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgroups\n\u001b[0;32m    610\u001b[0m )\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Given groups=1, weight of size [10, 1, 4, 4, 4], expected input[1, 128, 32, 32, 32] to have 1 channels, but got 128 channels instead"
     ]
    }
   ],
   "source": [
    "cur_step = 0\n",
    "for i in range(epochs):\n",
    "    # Make a checkpoint every 20 epochs\n",
    "    if i % 20 == 0:\n",
    "        torch.save(gen.state_dict(), PATH_CHECKPOINTS_GEN + f'/gen_{i}.pth')\n",
    "        torch.save(dis.state_dict(), PATH_CHECKPOINTS_DIS + f'/dis_{i}.pth')\n",
    "    \n",
    "    for in_data, tg_data in tqdm(dl_tr):\n",
    "        dis_opt.zero_grad()\n",
    "        fake = gen(in_data)\n",
    "        o_fake = dis(in_data, fake)\n",
    "        o_real = dis(in_data, tg_data)\n",
    "        dis_loss = discriminator_loss(criterion, o_real, o_fake)\n",
    "        dis_loss.backward(retain_graph=True)\n",
    "        dis_opt.step()\n",
    "        \n",
    "        gen_opt.zero_grad()\n",
    "        fake = gen(in_data)\n",
    "        o_fake = dis(in_data, fake)\n",
    "        o_real = dis(in_data, tg_data)\n",
    "        gen_loss = generator_loss(criterion, o_real, o_fake, tg_data, fake, LAMBDA)\n",
    "        gen_loss.backward()\n",
    "        gen_opt.step()\n",
    "        \n",
    "        mean_discriminator_loss += dis_loss.item() / display_step\n",
    "        mean_generator_loss += gen_loss.item() / display_step\n",
    "        \n",
    "        if cur_step % display_step == 0 and cur_step > 0:\n",
    "            print(f'Step {cur_step}: Generator loss: {mean_generator_loss}, Discriminator loss: {mean_discriminator_loss}')\n",
    "            # plot_epoch(in_data[0][0], fake[0][0], tg_data[0][0])\n",
    "            mean_generator_loss = 0\n",
    "            mean_discriminator_loss = 0\n",
    "        cur_step += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1039666a",
   "metadata": {},
   "outputs": [],
   "source": [
    "obj = torch.stack([models_tr_x[3], ])\n",
    "pcs = gen(obj)\n",
    "\n",
    "obj = obj[0][0].detach().cpu().numpy() > 0\n",
    "pcs = pcs[0][0].detach().cpu().numpy() > 0\n",
    "\n",
    "ax = plt.figure().add_subplot(projection='3d')\n",
    "ax.voxels(obj, facecolors='darkslategray', alpha=0.5)\n",
    "ax.voxels(pcs & ~obj, facecolors='orange', edgecolors='darkorange')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "02320d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(dis.state_dict(), PATH_MODELS + '/dis.pth')\n",
    "torch.save(gen.state_dict(), PATH_MODELS + '/gen.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.1 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "vscode": {
   "interpreter": {
    "hash": "02e2fc71c271602ea74fb2f2e07d43869b3a0483046e1b1cb97bbd88e5fe9d95"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
